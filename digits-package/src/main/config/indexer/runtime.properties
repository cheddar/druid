#Logging configuration
druid.emitter=logging
druid.emitter.logging.loggerClass=LoggingEmitter
druid.emitter.logging.logLevel=info

#Zookeeper and Curator configuration
druid.curator.compress=false
druid.zk.service.sessionTimeoutMs=30000
druid.zk.service.host=$(zk_hosts)
druid.zk.paths.base=$(zk_basePath)
druid.zk.paths.discoveryPath=$(zk_discoveryPath)

#Metrics
druid.monitoring.emissionPeriod=PT1m
druid.monitoring.monitors=[]

#Server configuration
druid.host=$(YINST_HOSTNAME):$(indexerPort)
druid.port=$(indexerPort)
druid.service=overlord

#Jetty configuration
druid.server.http.numThreads=$(maxHttpConnections)
druid.server.http.maxIdleTime=PT5m

#Discovery config
druid.discovery.curator.path=/druid/discovery

#DB configuration for coordinator and indexer
druid.db.connector.pollDuration=
druid.db.connector.connectURI=$(dbConnectUri)
druid.db.connector.user=$(dbUser)
druid.db.connector.password=$(dbPassword)
druid.db.connector.createTables=true
druid.db.connector.useValidationQuery=false
druid.db.connector.validationQuery=SELECT 1

#Jackson config manager
druid.manager.config.pollDuration=PT1m

#indexing service discovery module
druid.selectors.indexing.serviceName=overlord

#data segment pusher/puller module
#types can be local, hdfs, s3, noop, cassandra
druid.storage.type=$(storageType)
druid.storage.storageDirectory=$(storageDirectory)

#Task Log module (indexing service)
druid.indexer.logs.type=file
druid.indexer.logs.directory=$(ROOT)/logs/$(YINST_PKGNAME)/tasklogs

#indexer configuration
druid.indexer.runner.type=local
druid.indexer.storage.type=$(indexerStorageType)
druid.indexer.queue.maxSize=2000000000
druid.indexer.queue.startDelay=PT1M
druid.indexer.queue.restartDelay=PT30S
druid.indexer.queue.storageSyncRate=PT1M

#indexer autoscaling configuration
druid.indexer.autoscale.doAutoscale=false
druid.indexer.autoscale.strategy=noop

#indexer middlemanager configuration
druid.worker.ip=localhost
druid.worker.version=0
druid.worker.capacity=$(maxIndexerTasks)
druid.indexer.runner.compressZnodes=false
druid.indexer.runner.maxZnodeBytes=524288
druid.indexer.runner.taskDir=$(indexerTaskDir)
druid.indexer.runner.javaCommand=java
druid.indexer.runner.javaOpts=$(peonJavaOpts)
druid.indexer.runner.startPort=$(peonStartPort)

#indexer peon configuration
druid.peon.mode=remote
druid.indexer.task.baseDir=$(indexerBaseWorkingDir)
druid.indexer.task.baseTaskDir=$(indexerBaseTaskDir)
druid.indexer.task.hadoopWorkingPath=$(indexerHadoopWorkingPath)
druid.indexer.task.defaultRowFlushBoundary=50000
druid.indexer.task.chathandler.type=noop
druid.peon.taskActionClient.retry.minWait=PT1M
druid.peon.taskActionClient.retry.maxwait=PT10M
druid.peon.taskActionClient.retry.maxRetryCount=10

druid.indexer.runner.allowedPrefixes=["com.metamx", "druid", "io.druid", "user.timezone", "file.encoding", "hadoop"]

#hadoop properties
druid.indexer.task.defaultHadoopCoordinates=[]
druid.indexer.fork.property.hadoop.mapreduce.job.queuename=$(queueName)
druid.indexer.fork.property.hadoop.mapreduce.job.acl-view-job=*
druid.indexer.fork.property.hadoop.mapreduce.map.memory.mb=$(indexerReducerMem) 
druid.indexer.fork.property.hadoop.mapreduce.reduce.memory.mb=$(indexerReducerMem) 
druid.indexer.fork.property.hadoop.mapreduce.map.java.opts=-XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:CMSInitiatingOccupancyFraction=10 -Duser.timezone=UTC
druid.indexer.fork.property.hadoop.mapreduce.reduce.java.opts=$(indexerReducerJavaOpts) -Duser.timezone=UTC
druid.indexer.fork.property.hadoop.yarn.app.mapreduce.am.env=JAVA_HOME=/home/gs/java/jdk64/current
druid.indexer.fork.property.hadoop.mapreduce.map.env=JAVA_HOME=/home/gs/java/jdk64/current
druid.indexer.fork.property.hadoop.mapreduce.reduce.env=JAVA_HOME=/home/gs/java/jdk64/current

druid.processing.buffer.sizeBytes=2
druid.processing.numThreads=536870912

